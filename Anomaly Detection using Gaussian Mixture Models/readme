In this project, I implemented Gaussian Mixture Models (GMMs) to identify anomalies in a forest cover dataset featuring 300,000 data points. The data exhibited a significant class imbalance, with only 0.96% of points labeled as anomalies. After initial data preprocessing and visualization to understand feature distributions and their relation to anomaly status, I trained single-component GMMs on individual features, using metrics such as AUC and F1-score for model evaluation.

To enhance model performance, I explored multivariate GMMs, training them on combinations of features. This approach allowed for capturing more complex patterns and interactions between features, crucial for improving anomaly detection in highly dimensional data. I experimented with different numbers of components in the GMMs to best model the distribution of normal and anomalous data within the multivariate space.

The iterative process of training and validating models on different feature sets and component configurations led to a selection of the most effective models. The final ensemble of models was tested, achieving an impressive 95.6% F1-score on the test set, demonstrating the robustness and accuracy of the multivariate GMM approach in handling complex, imbalanced datasets.
